{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "4c306b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xlsxwriter\n",
    "import cv2\n",
    "import matplotlib.colors as cs\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import urllib\n",
    "from pyinaturalist import get_observations\n",
    "import urllib.request\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# Color Hex Codes to Color Names\n",
    "from scipy.spatial import KDTree\n",
    "from webcolors import (\n",
    "    CSS3_HEX_TO_NAMES,\n",
    "    hex_to_rgb,\n",
    ")\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "#import matplotlib.pyplot as plot\n",
    "#import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922b0335",
   "metadata": {},
   "source": [
    "### Create a new structured dataframe using the user id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "b49e7768",
   "metadata": {},
   "outputs": [],
   "source": [
    "iNaturalist_Username = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "5d82d206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>quality_grade</th>\n",
       "      <th>time_observed_at</th>\n",
       "      <th>taxon_geoprivacy</th>\n",
       "      <th>annotations</th>\n",
       "      <th>uuid</th>\n",
       "      <th>id</th>\n",
       "      <th>cached_votes_total</th>\n",
       "      <th>identifications_most_agree</th>\n",
       "      <th>species_guess</th>\n",
       "      <th>...</th>\n",
       "      <th>observation_photos</th>\n",
       "      <th>faves</th>\n",
       "      <th>non_owner_ids</th>\n",
       "      <th>observed_on</th>\n",
       "      <th>square_image_url</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>site_url</th>\n",
       "      <th>User</th>\n",
       "      <th>Image_Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>casual</td>\n",
       "      <td>2022-05-19T11:37:00+08:00</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>6b13cbf1-0b85-4b0d-8cc3-60e7eae89b07</td>\n",
       "      <td>117739830</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Flowering Plants</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'id': 185644888, 'position': 0, 'uuid': 'ddc...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2022-05-19 11:37:00+08:00</td>\n",
       "      <td>https://inaturalist-open-data.s3.amazonaws.com...</td>\n",
       "      <td>31.173552</td>\n",
       "      <td>121.443451</td>\n",
       "      <td>https://www.inaturalist.org/observations/11773...</td>\n",
       "      <td>jiayuelin</td>\n",
       "      <td>https://inaturalist-open-data.s3.amazonaws.com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>research</td>\n",
       "      <td>2022-05-19T11:37:00+08:00</td>\n",
       "      <td>open</td>\n",
       "      <td>[]</td>\n",
       "      <td>e9108ab1-25e5-455b-b155-1ae9b6ffbcdc</td>\n",
       "      <td>117739833</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>五爪金龙</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'id': 185644891, 'position': 0, 'uuid': '5b8...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'hidden': False, 'disagreement': False, 'fla...</td>\n",
       "      <td>2022-05-19 11:37:00+08:00</td>\n",
       "      <td>https://inaturalist-open-data.s3.amazonaws.com...</td>\n",
       "      <td>31.184283</td>\n",
       "      <td>121.435212</td>\n",
       "      <td>https://www.inaturalist.org/observations/11773...</td>\n",
       "      <td>jiayuelin</td>\n",
       "      <td>https://inaturalist-open-data.s3.amazonaws.com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>casual</td>\n",
       "      <td>2022-05-19T11:37:00+08:00</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>b9d8f17d-1815-4457-b671-c10822dcc34c</td>\n",
       "      <td>117739837</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Plants</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'id': 185644894, 'position': 0, 'uuid': '59d...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2022-05-19 11:37:00+08:00</td>\n",
       "      <td>https://inaturalist-open-data.s3.amazonaws.com...</td>\n",
       "      <td>31.177380</td>\n",
       "      <td>121.436928</td>\n",
       "      <td>https://www.inaturalist.org/observations/11773...</td>\n",
       "      <td>jiayuelin</td>\n",
       "      <td>https://inaturalist-open-data.s3.amazonaws.com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 67 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new observation\n",
    "observations = get_observations(user_id=iNaturalist_Username, page='all')\n",
    "\n",
    "# df_list is used to append all the observations into a dataframe\n",
    "df_list = []\n",
    "# df_url is used to store image urls\n",
    "df_url = []\n",
    "# df_lat_long is used to store latitude and longitude\n",
    "df_lat = []\n",
    "df_long = []\n",
    "# df_site_url is used to store site url\n",
    "df_site_url = []\n",
    "# Store user id and login\n",
    "# df_user_id = []\n",
    "df_user_login = []\n",
    "# Store public/positional accuracy\n",
    "# df_pos_acc = []\n",
    "# df_pub_pos_acc = []\n",
    "# Store annotations\n",
    "# df_annotations = []\n",
    "# Store place guess\n",
    "df_place = []\n",
    "#Store time_observed_at\n",
    "# df_time = []\n",
    "\n",
    "for obs in observations['results']:\n",
    "    # From dict to dataframe\n",
    "    df = pd.DataFrame.from_dict(obs, orient='index')\n",
    "    # Get image urls\n",
    "    if obs.get('photos') is not None:\n",
    "        image_url = obs.get('photos')[0].get('url')\n",
    "    else:\n",
    "        image_url = 'None'\n",
    "    # Get latitude and longitude\n",
    "    # Get positional accuracy\n",
    "    if obs.get('location') is not None:\n",
    "        lat = obs.get('location')[0]\n",
    "        lon = obs.get('location')[1]\n",
    "        # pos_acc = obs.get('positional_accuracy')\n",
    "        # pub_pos_acc = obs.get('public_positional_accuracy')\n",
    "    else:\n",
    "        lat = '             40.343137'\n",
    "        lon = '             74.655070'\n",
    "    # Get annotations\n",
    "    # if obs.get('annotations') is not None:\n",
    "    #     anno = obs.get('annotations')\n",
    "    # else:\n",
    "    #     anno = 'Princeton University'\n",
    "    # anno = obs.get('annotations')\n",
    "        # pos_acc = 'None'\n",
    "        # pub_pos_acc = 'None'\n",
    "    \n",
    "    # Get place guess\n",
    "    if obs.get('place_guess') is not None and lat != '             40.343137' and lon != '             74.655070':\n",
    "        place_guess = obs.get('place_guess')\n",
    "    else:\n",
    "        place_guess = 'Princeton University'    \n",
    "    \n",
    "    # Get site url\n",
    "    if obs.get('uri') is not None:\n",
    "        site_url = obs.get('uri')\n",
    "    else:\n",
    "        site_url = 'None'\n",
    "    # Get user id and login\n",
    "    if obs.get('user') is not None:\n",
    "        #user_id = obs.get('user').get('id')\n",
    "        user_login = obs.get('user').get('login')\n",
    "    else:\n",
    "        #user_id = 'None'\n",
    "        user_login = 'None'\n",
    "    # if obs.get('time_observed_at') is not None:\n",
    "    #     time_at = obs.get('time_observed_at')\n",
    "    # else:\n",
    "    #     time_at = 'None'\n",
    "        \n",
    "    # Transpose the dataframe so that rows represent images and columns are variables\n",
    "    # that describe the images.\n",
    "    df = df.transpose()\n",
    "    df_list.append(df)\n",
    "    df_url.append(image_url)\n",
    "    df_lat.append(lat)\n",
    "    df_long.append(lon)\n",
    "    df_site_url.append(site_url)\n",
    "    #df_user_id.append(user_id)\n",
    "    df_user_login.append(user_login)\n",
    "    # df_pos_acc.append(pos_acc)\n",
    "    # df_pub_pos_acc.append(pub_pos_acc)\n",
    "    # df_annotations.append(anno)\n",
    "    df_place.append(place_guess)\n",
    "    # df_time.append(time_at)\n",
    "\n",
    "# Concatenate all dataframes\n",
    "iNatStruct = pd.concat(df_list)\n",
    "\n",
    "# Add updated columns to the dataframe\n",
    "iNatStruct['square_image_url'] = df_url\n",
    "iNatStruct['latitude'] = df_lat\n",
    "iNatStruct['longitude'] = df_long\n",
    "iNatStruct['site_url'] = df_site_url\n",
    "#iNatStruct['user_id'] = df_user_id\n",
    "iNatStruct['User'] = df_user_login\n",
    "# iNatStruct['positional_accuracy'] = df_pos_acc\n",
    "# iNatStruct['public_positional_accuracy'] = df_pub_pos_acc\n",
    "# iNatStruct['annotations'] = df_annotations\n",
    "iNatStruct['place_guess'] = df_place\n",
    "# iNatStruct['time_observed_at'] = df_time\n",
    "\n",
    "# Replace image size from 'square' to 'medium' and 'large'\n",
    "iNatStruct['Image_Link'] = iNatStruct['square_image_url'].replace('square', 'medium', regex=True)\n",
    "# iNatStruct['large_image_url'] = iNatStruct['square_image_url'].replace('square', 'large', regex=True)\n",
    "\n",
    "# Reset index and drop the old index\n",
    "iNatStruct = iNatStruct.reset_index()\n",
    "# iNatStruct = iNatStruct.drop(['index'], axis=1)\n",
    "\n",
    "iNatStruct.head(3)\n",
    "# observations['results']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f780a3",
   "metadata": {},
   "source": [
    "## Continue on initial structured data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "e0da5eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'11:37:00+08:00'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'11:37:00+08:00'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split time_observed_at into date and time\n",
    "def convertT(time):\n",
    "    time = time.replace('T',' ')\n",
    "    return time\n",
    "\n",
    "iNatStruct.time_observed_at.map(lambda t: convertT(t).split())[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "12436cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use lambda function to split time_observed_at into date and time\n",
    "for i in iNatStruct.time_observed_at:    \n",
    "    iNatStruct['observed_date'] = (iNatStruct.time_observed_at.map(lambda t: convertT(t).split()[0]))\n",
    "    iNatStruct['observed_time'] = (iNatStruct.time_observed_at.map(lambda t: convertT(t).split()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "afe8be2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift columns observed_date and observed_time to position 1 and 2\n",
    "column1 = iNatStruct.pop('observed_date')\n",
    "column2 = iNatStruct.pop('observed_time')\n",
    "  \n",
    "# insert column using insert\n",
    "iNatStruct.insert(1, 'observed_date', column1)\n",
    "iNatStruct.insert(2, 'observed_time', column2)\n",
    "\n",
    "# delete time_observed_at column\n",
    "del iNatStruct[\"time_observed_at\"]\n",
    "del iNatStruct[\"observed_on\"]\n",
    "#del iNatStruct[\"observed_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "f0901c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift location column to last column\n",
    "column1 = iNatStruct.pop('location')\n",
    "  \n",
    "# insert location column using insert\n",
    "iNatStruct.insert(len(iNatStruct) - 1, 'location', column1) \n",
    "# not sure why it's not moving the column to last position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "d21a0f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the characters after '-'\n",
    "def removeChar(char):\n",
    "    ch = \"-\"\n",
    "    char = char.split(ch, 1)[0]\n",
    "    return char\n",
    "\n",
    "# Use lambda function to remove the characters after '-'\n",
    "iNatStruct['observed_time'] = iNatStruct.observed_time.map(lambda t: removeChar(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "af3430cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the characters after '+'\n",
    "def removeChara(char):\n",
    "    ch = \"+\"\n",
    "    char = char.split(ch, 1)[0]\n",
    "    return char\n",
    "\n",
    "# Use lambda function to remove the characters after '+'\n",
    "iNatStruct['observed_time'] = iNatStruct.observed_time.map(lambda t: removeChara(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "c4decf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to Second\n",
    "def timeToSec(time):\n",
    "    time = time.split(':')\n",
    "    sec = int(time[0])*3600 + int(time[1])*60 + int(time[2])\n",
    "    return sec\n",
    "\n",
    "# Use lambda function to convert time to second\n",
    "iNatStruct['Seconds'] = iNatStruct.observed_time.map(lambda t: timeToSec(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "265d4395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_Label</th>\n",
       "      <th>Image_Link</th>\n",
       "      <th>Species</th>\n",
       "      <th>User</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Seconds</th>\n",
       "      <th>Place</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p1</td>\n",
       "      <td>https://inaturalist-open-data.s3.amazonaws.com...</td>\n",
       "      <td>Flowering Plants</td>\n",
       "      <td>jiayuelin</td>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>11:37:00</td>\n",
       "      <td>41820</td>\n",
       "      <td>Xuhui District, Shanghai, China</td>\n",
       "      <td>31.173552</td>\n",
       "      <td>121.443451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p2</td>\n",
       "      <td>https://inaturalist-open-data.s3.amazonaws.com...</td>\n",
       "      <td>五爪金龙</td>\n",
       "      <td>jiayuelin</td>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>11:37:00</td>\n",
       "      <td>41820</td>\n",
       "      <td>Xuhui District, Shanghai, China</td>\n",
       "      <td>31.184283</td>\n",
       "      <td>121.435212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p3</td>\n",
       "      <td>https://inaturalist-open-data.s3.amazonaws.com...</td>\n",
       "      <td>Plants</td>\n",
       "      <td>jiayuelin</td>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>11:37:00</td>\n",
       "      <td>41820</td>\n",
       "      <td>Xuhui District, Shanghai, China</td>\n",
       "      <td>31.177380</td>\n",
       "      <td>121.436928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p4</td>\n",
       "      <td>https://inaturalist-open-data.s3.amazonaws.com...</td>\n",
       "      <td>Plants</td>\n",
       "      <td>jiayuelin</td>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>11:37:00</td>\n",
       "      <td>41820</td>\n",
       "      <td>Xuhui District, Shanghai, China</td>\n",
       "      <td>31.172093</td>\n",
       "      <td>121.434525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename columns\n",
    "iNatStruct.rename(columns = {'species_guess':'Species', 'observed_date':'Date', 'observed_time':'Time', \n",
    "                             'place_guess':'Place', 'latitude':'Lat', 'longitude':'Long'}, inplace = True)\n",
    "\n",
    "# The structured dataframe is now ready\n",
    "iNatStruct = iNatStruct[[\"Image_Link\", \"Species\", \"User\", \"Date\", \"Time\", \"Seconds\", \"Place\", \"Lat\", \"Long\"]]\n",
    "\n",
    "# Sort DataFrame by date and time\n",
    "iNatStruct = iNatStruct.sort_values(['Date', 'Time'], ascending = [True, True])\n",
    "\n",
    "# Add p_ column\n",
    "p_lab = ['p'+str(s+1) for s in iNatStruct.index]\n",
    "iNatStruct.insert(0, \"Image_Label\", p_lab)\n",
    "\n",
    "# Sort DataFrame by Image_Label\n",
    "iNatStruct = iNatStruct.sort_values('Image_Label', key=lambda x: x.str.extract('(\\d+)').squeeze().astype(int))\n",
    "\n",
    "iNatStruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0565bf7b",
   "metadata": {},
   "source": [
    "# Jubilee's color observation code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b5eace",
   "metadata": {},
   "source": [
    "## Show percentage of dominant (most frequent) color within image using kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "bd1f23c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def centroid_histogram(clt):\n",
    "    # grab the number of different clusters and create a histogram\n",
    "    # based on the number of pixels assigned to each cluster\n",
    "    numLabels = np.arange(0, len(np.unique(clt.labels_)) + 1)\n",
    "    (hist, _) = np.histogram(clt.labels_, bins=numLabels)\n",
    "\n",
    "    # normalize the histogram, so that it sums to one\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= hist.sum()\n",
    "    #hist = \"{:.2f}\".format(hist)\n",
    "    \n",
    "    # return the histogram\n",
    "    return hist\n",
    "\n",
    "\n",
    "#hist = centroid_histogram(clt)\n",
    "#print(hist)\n",
    "#type(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3737e74",
   "metadata": {},
   "source": [
    "### Define Color Palette Display Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "2df03d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def palette(clusters):\n",
    "    width = 300\n",
    "    palette = np.zeros((50, width, 3), np.uint8)\n",
    "    steps = width/clusters.cluster_centers_.shape[0]\n",
    "    for idx, centers in enumerate(clusters.cluster_centers_):\n",
    "        palette[:, int(idx*steps):(int((idx+1)*steps)), :] = centers\n",
    "    return palette"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e6de0e",
   "metadata": {},
   "source": [
    "## Implement RGB color column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "448fbb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column name list \n",
    "col_names =  ['R1', 'G1', 'B1', 'R2', 'G2', 'B2', 'R3', 'G3', 'B3']\n",
    "col_names1 =  ['Set1(R,G,B)', 'Set2(R,G,B)', 'Set3(R,G,B)']\n",
    "col_names2 =  ['Set1(R,G,B,Prop)', 'Set2(R,G,B,Prop)', 'Set3(R,G,B,Prop)']\n",
    "  \n",
    "# create an empty dataframe with columns\n",
    "RGBdf = pd.DataFrame(columns = col_names)\n",
    "#PERdf = pd.DataFrame(columns = col_names1) \n",
    "colorDF = pd.DataFrame(columns = col_names2) \n",
    "\n",
    "hexDF = pd.DataFrame(columns = col_names1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "714819c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34b8da3",
   "metadata": {},
   "source": [
    "## Implement Color Names Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "7dea2f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert RGB to Color Names\n",
    "def convert_rgb_to_names(rgb_tuple):\n",
    "    \n",
    "    # a dictionary of all the hex and their respective names in css3\n",
    "    css3_db = CSS3_HEX_TO_NAMES\n",
    "    names = []\n",
    "    rgb_values = []\n",
    "    for color_hex, color_name in css3_db.items():\n",
    "        names.append(color_name)\n",
    "        rgb_values.append(hex_to_rgb(color_hex))\n",
    "    \n",
    "    kdt_db = KDTree(rgb_values)\n",
    "    distance, index = kdt_db.query(rgb_tuple)\n",
    "    return f'{names[index]}'\n",
    "\n",
    "# Testing\n",
    "# print(convert_rgb_to_names((191.3446284379988,206.0364699381563,221.936275645711)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b906ed80",
   "metadata": {},
   "source": [
    "- n_init: int, default=10\n",
    "- max_iter: int, default=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "aa002489",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18334\\AppData\\Local\\Temp\\ipykernel_7568\\123338797.py:146: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  colorDF = colorDF.append(pd.DataFrame([colors], columns=col_names2),\n",
      "C:\\Users\\18334\\AppData\\Local\\Temp\\ipykernel_7568\\123338797.py:146: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  colorDF = colorDF.append(pd.DataFrame([colors], columns=col_names2),\n",
      "C:\\Users\\18334\\AppData\\Local\\Temp\\ipykernel_7568\\123338797.py:146: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  colorDF = colorDF.append(pd.DataFrame([colors], columns=col_names2),\n",
      "C:\\Users\\18334\\AppData\\Local\\Temp\\ipykernel_7568\\123338797.py:146: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  colorDF = colorDF.append(pd.DataFrame([colors], columns=col_names2),\n"
     ]
    }
   ],
   "source": [
    "#start = time.time()\n",
    "\n",
    "hex_code = []\n",
    "ord_hex_code = []\n",
    "r_pix = []\n",
    "g_pix = []\n",
    "b_pix = []\n",
    "per = []\n",
    "\n",
    "cluster_count = 3\n",
    "clt = KMeans(n_clusters=cluster_count, n_init = 7, max_iter = 150) # kmeans to find color cluster\n",
    "#clt = MiniBatchKMeans(n_clusters = cluster_count)\n",
    "#clustNum = 3 #set number of cluster for kmeans to be 3\n",
    "#clt = KMeans(n_clusters=clustNum) # kmeans to find color cluster\n",
    "#clt = KMeans(n_clusters=clustNum, n_init = 5, max_iter = 100) # kmeans to find color cluster\n",
    "\n",
    "for img in iNatStruct[\"Image_Link\"]: \n",
    "    req = urllib.request.urlopen(img)\n",
    "    arr = np.asarray(bytearray(req.read()), dtype=np.uint8)\n",
    "    #imgNat_con = cv2.imdecode(arr, -1)\n",
    "    imgNat = cv2.imdecode(arr, -1)\n",
    "    imgray = cv2.cvtColor(imgNat, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(imgray, (5,5), 0)\n",
    "    thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    #cv2.drawContours(imgNat_con, contours, -1, (0, 255, 0), 3)\n",
    "    #plt.imshow(imgNat_con)\n",
    "    \n",
    "    imgNat = cv2.cvtColor(imgNat,cv2.COLOR_BGR2RGB) #convert bgr to rgb\n",
    "    \n",
    "    # grab largest contour\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "\n",
    "# create a black `mask` the same size as the original grayscale image \n",
    "    mask = np.zeros_like(imgray)\n",
    "# fill the new mask with the shape of the largest contour\n",
    "# all the pixels inside that area will be white \n",
    "#cv2.fillPoly(mask, [contours[0]], 255) >> grabs smallest contour\n",
    "    cv2.fillPoly(mask, [largest_contour], 255)\n",
    "# create a copy of the current mask\n",
    "    res_mask = np.copy(mask)\n",
    "    res_mask[mask == 0] = cv2.GC_BGD # obvious background pixels\n",
    "    res_mask[mask == 255] = cv2.GC_PR_BGD # probable background pixels\n",
    "    res_mask[mask == 255] = cv2.GC_FGD # obvious foreground pixels\n",
    "\n",
    "# create a mask for obvious and probable foreground pixels\n",
    "# all the obvious foreground pixels will be white and all the probable foreground pixels will be black\n",
    "    mask2 = np.where((res_mask == cv2.GC_FGD) | (res_mask == cv2.GC_PR_FGD),255,0).astype('uint8')\n",
    "\n",
    "# create `new_mask3d` from `mask2` but with 3 dimensions instead of 2\n",
    "    new_mask3d = np.repeat(mask2[:, :, np.newaxis], 3, axis=2)\n",
    "    mask3d = new_mask3d\n",
    "    mask3d[new_mask3d > 0] = 255.0\n",
    "    mask3d[mask3d > 255] = 255.0\n",
    "# apply Gaussian blurring to smoothen out the edges a bit\n",
    "# `mask3d` is the final foreground mask (not extracted foreground image)\n",
    "    mask3d = cv2.GaussianBlur(mask3d, (5, 5), 0)\n",
    "    #show('Foreground mask', mask3d)\n",
    "\n",
    "# create the foreground image by zeroing out the pixels where `mask2` has black pixels\n",
    "    foreground = np.copy(imgNat).astype(float)\n",
    "    #foreground = np.copy(imgNat1).astype(float)\n",
    "    foreground[mask2 == 0] = 0\n",
    "    #show('Foreground', foreground.astype(np.uint8))\n",
    "    #plt.imshow(foreground.astype(np.uint8))\n",
    "    \n",
    "    # work with black background\n",
    "    imgfile = Image.fromarray(foreground.astype(np.uint8))\n",
    "    # Only pass through non-transparent pixels, i.e. those where A!=0 in the RGBA quad\n",
    "    na = np.array([f for f in imgfile.getdata() if f[2] !=0], np.uint8)\n",
    "    \n",
    "    #cluster_count = 3\n",
    "    #clusters = KMeans(n_clusters=cluster_count, n_init = 5, max_iter = 100) # kmeans to find color cluster\n",
    "    #clusters = MiniBatchKMeans(n_clusters = cluster_count)\n",
    "    clt.fit(na)\n",
    "    \n",
    "    #n_img = np.reshape(imgNat,(imgNat.shape[0]*imgNat.shape[1],3)) #reshape img array\n",
    "    #clt.fit(n_img)\n",
    "    \n",
    "    #labels = np.unique(clusters.labels_) #get unique value of labels in kmeans\n",
    "    #hist,_ = np.histogram(clusters.labels_,bins=np.arange(len(labels)+1)) #find pixel numbers of each color\n",
    "    npbins = np.arange(0, cluster_count + 1)\n",
    "    hist = np.histogram(clt.labels_, bins=npbins)\n",
    "    labels = np.unique(clt.labels_)\n",
    "\n",
    "    #hexlabels2 = []\n",
    "    colors_w_black_back = []\n",
    "    colors = [] # list to hold color\n",
    "    #rgbVals = [] \n",
    "    hexlabels = [] # list to hold hex color code\n",
    "    #hexLabOrder = [] # ordered hex color code with proportion\n",
    "    c = []\n",
    "    #c_hex=[]\n",
    "    \n",
    "    # add percentage >> new position\n",
    "    histPer = list(centroid_histogram(clt))\n",
    "    per.append([round(percent,2) for percent in histPer])\n",
    "    \n",
    "    #get the main color\n",
    "    for i in range(clt.cluster_centers_.shape[0]):\n",
    "        clust_cent = clt.cluster_centers_[i]\n",
    "        colors.append(tuple(clust_cent) + (histPer[i], ))\n",
    "        colors = sorted(colors, key = lambda element : element[3], reverse=True)\n",
    "        \n",
    "        # add hex_labels    \n",
    "        #hexlabels.append(cs.to_hex(tuple(clust_cent/255)))\n",
    "        #c_hex.append(tuple(clust_cent/255))\n",
    "        \n",
    "        # ordered hex color code with proportion\n",
    "        c.append(tuple(clust_cent/255) + (histPer[i], ))\n",
    "        c = sorted(c, key = lambda element : element[3], reverse=True)\n",
    "        #output = list(map(lambda elem: elem[0:3], c))\n",
    "        #hexLabOrder.append(cs.to_hex(output[i]))\n",
    "        \n",
    "        # add individual RGB values\n",
    "        #for j in range(cluster_count):\n",
    "        #    rgbVals.append(clust_cent[j])\n",
    "        \n",
    "        #print(tuple(clt.cluster_centers_[i]/255))\n",
    "        \n",
    "    output = list(map(lambda elem: elem[0:3], c))\n",
    "    #print(output)\n",
    "   # rgbVals = [rgbVals]\n",
    "    \n",
    "    # append RGB\n",
    "    #RGBdf = RGBdf.append(pd.DataFrame(rgbVals, columns=['R1', 'G1', 'B1', 'R2', 'G2', 'B2', 'R3', 'G3', 'B3']), \n",
    "     #              ignore_index = True)\n",
    "    \n",
    "    # Store RGB Color Names\n",
    "#    Color_Names_1 = []\n",
    "#    Color_Names_2 = []\n",
    "#    Color_Names_3 = []\n",
    "#    for i in RGBdf.index:\n",
    "        # RGB1\n",
    "#        rgb1 = RGBdf.iloc[i, 0:3]\n",
    "#        Color_Names_1.append(convert_rgb_to_names(rgb1))\n",
    "        # RGB2\n",
    "#        rgb2 = RGBdf.iloc[i, 3:6]\n",
    "#        Color_Names_2.append(convert_rgb_to_names(rgb2))\n",
    "        # RGB3\n",
    "#        rgb3 = RGBdf.iloc[i, 6:9]\n",
    "#        Color_Names_3.append(convert_rgb_to_names(rgb3))\n",
    "    \n",
    "    # append color >> uncomment\n",
    "    colorDF = colorDF.append(pd.DataFrame([colors], columns=col_names2), \n",
    "                   ignore_index = True)\n",
    "    \n",
    "    #hexDF = hexDF.append(pd.DataFrame([[matplotlib.colors.to_hex( output[i]) for i in range(cluster_count)]], \n",
    "    #                                  columns = col_names1), ignore_index=True)\n",
    "    #hex_code.append(hexlabels)\n",
    "    ord_hex_code.append([matplotlib.colors.to_hex( output[i]) for i in range(cluster_count)])\n",
    "    \n",
    "    \n",
    "    ## color check using pie chart\n",
    "    #labels_pie = np.unique(clt.labels_) # labels\n",
    "    #hist_pie,_ = np.histogram(clt.labels_,bins=np.arange(len(labels_pie)+1)) # pixel nums\n",
    "    #c_pie = [] \n",
    "    #h_pie = []\n",
    "    #for i in range(clt.cluster_centers_.shape[0]):\n",
    "    #  c_pie.append(tuple(clt.cluster_centers_[i]/255))\n",
    "    #  h_pie.append(cs.to_hex(tuple(clt.cluster_centers_[i]/255)))\n",
    "\n",
    "    #plt.pie(hist_pie,labels=h_pie,colors=c_pie,autopct='%1.1f%%')\n",
    "    #plt.axis('equal')\n",
    "    #plt.show()\n",
    "\n",
    "#end = time.time()\n",
    "#elapsedTime = round(end-start,3)\n",
    "#print(\"new code block took\", elapsedTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "4b233d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(matplotlib.colors.to_hex([ 191.3/255, 206.0/255, 221.9/255]))\n",
    "#print(matplotlib.colors.to_hex([ 191.3/255, 206.0/255, 221.9/255]))\n",
    "#print(matplotlib.colors.to_hex([ 0.7, 0.321, 0.3, 0.5 ], keep_alpha=True))\n",
    "#print(matplotlib.colors.to_rgb(\"#aabbcc\"))\n",
    "#rgb1 = matplotlib.colors.to_rgb(\"#798961\")\n",
    "#rgb2 = matplotlib.colors.to_rgb(\"#6c7c61\")\n",
    "#print(convert_rgb_to_names(tuple([rgb1[i]*255 for i in range(3)])))\n",
    "#print(convert_rgb_to_names(tuple([rgb2[i]*255 for i in range(3)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "003ca202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print color palette of last imgNat\n",
    "#plt.imshow(palette(clt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63622d6a",
   "metadata": {},
   "source": [
    "### Create R,G,B,Prop columns and add them to iNatStruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "b3e76389",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_1 =  ['R1', 'G1', 'B1', 'Prop1']\n",
    "col_2 =  ['R2', 'G2', 'B2', 'Prop2']\n",
    "col_3 =  ['R3', 'G3', 'B3', 'Prop3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "92bfb57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedColorDF = pd.DataFrame()\n",
    "combinedColorDF[col_1] = pd.DataFrame(colorDF['Set1(R,G,B,Prop)'].tolist(), index=colorDF.index)\n",
    "combinedColorDF[col_2] = pd.DataFrame(colorDF['Set2(R,G,B,Prop)'].tolist(), index=colorDF.index)\n",
    "combinedColorDF[col_3] = pd.DataFrame(colorDF['Set3(R,G,B,Prop)'].tolist(), index=colorDF.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "b3a530e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store RGB Color Names\n",
    "Color_Names_1 = []\n",
    "Color_Names_2 = []\n",
    "Color_Names_3 = []\n",
    "\n",
    "for i in combinedColorDF.index:\n",
    "    # RGB1\n",
    "    rgb1 = combinedColorDF.iloc[i, 0:3]\n",
    "    Color_Names_1.append(convert_rgb_to_names(rgb1))\n",
    "    # RGB2\n",
    "    rgb2 = combinedColorDF.iloc[i, 4:7]\n",
    "    Color_Names_2.append(convert_rgb_to_names(rgb2))\n",
    "    # RGB3\n",
    "    rgb3 = combinedColorDF.iloc[i, 8:11]\n",
    "    Color_Names_3.append(convert_rgb_to_names(rgb3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "c2b22565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-set index to be same as iNatStruct\n",
    "#RGBdf = RGBdf.set_index(iNatStruct.index)\n",
    "combinedColorDF = combinedColorDF.set_index(iNatStruct.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "e9391bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append method\n",
    "#result = pd.concat([iNatStruct, RGBdf, PERdf], axis=1)\n",
    "result = pd.concat([iNatStruct, combinedColorDF], axis=1)\n",
    "#display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "21b36377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_Label</th>\n",
       "      <th>Image_Link</th>\n",
       "      <th>Species</th>\n",
       "      <th>User</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Seconds</th>\n",
       "      <th>Place</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>...</th>\n",
       "      <th>Prop1</th>\n",
       "      <th>R2</th>\n",
       "      <th>G2</th>\n",
       "      <th>B2</th>\n",
       "      <th>Prop2</th>\n",
       "      <th>R3</th>\n",
       "      <th>G3</th>\n",
       "      <th>B3</th>\n",
       "      <th>Prop3</th>\n",
       "      <th>Hex_Color_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p1</td>\n",
       "      <td>https://inaturalist-open-data.s3.amazonaws.com...</td>\n",
       "      <td>Flowering Plants</td>\n",
       "      <td>jiayuelin</td>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>11:37:00</td>\n",
       "      <td>41820</td>\n",
       "      <td>Xuhui District, Shanghai, China</td>\n",
       "      <td>31.173552</td>\n",
       "      <td>121.443451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523124</td>\n",
       "      <td>62.477876</td>\n",
       "      <td>114.394336</td>\n",
       "      <td>3.942301</td>\n",
       "      <td>0.277631</td>\n",
       "      <td>124.074675</td>\n",
       "      <td>171.863670</td>\n",
       "      <td>59.332842</td>\n",
       "      <td>0.199246</td>\n",
       "      <td>[#5c9909, #3e7204, #7cac3b]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p2</td>\n",
       "      <td>https://inaturalist-open-data.s3.amazonaws.com...</td>\n",
       "      <td>五爪金龙</td>\n",
       "      <td>jiayuelin</td>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>11:37:00</td>\n",
       "      <td>41820</td>\n",
       "      <td>Xuhui District, Shanghai, China</td>\n",
       "      <td>31.184283</td>\n",
       "      <td>121.435212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564373</td>\n",
       "      <td>62.094764</td>\n",
       "      <td>76.742753</td>\n",
       "      <td>31.273897</td>\n",
       "      <td>0.294720</td>\n",
       "      <td>171.134636</td>\n",
       "      <td>144.465195</td>\n",
       "      <td>209.270963</td>\n",
       "      <td>0.140907</td>\n",
       "      <td>[#1f2b0d, #3e4d1f, #ab90d1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p3</td>\n",
       "      <td>https://inaturalist-open-data.s3.amazonaws.com...</td>\n",
       "      <td>Plants</td>\n",
       "      <td>jiayuelin</td>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>11:37:00</td>\n",
       "      <td>41820</td>\n",
       "      <td>Xuhui District, Shanghai, China</td>\n",
       "      <td>31.177380</td>\n",
       "      <td>121.436928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.441711</td>\n",
       "      <td>43.527467</td>\n",
       "      <td>81.567450</td>\n",
       "      <td>32.532080</td>\n",
       "      <td>0.297886</td>\n",
       "      <td>73.300605</td>\n",
       "      <td>124.152255</td>\n",
       "      <td>61.590377</td>\n",
       "      <td>0.260402</td>\n",
       "      <td>[#152412, #2c5221, #497c3e]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p4</td>\n",
       "      <td>https://inaturalist-open-data.s3.amazonaws.com...</td>\n",
       "      <td>Plants</td>\n",
       "      <td>jiayuelin</td>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>11:37:00</td>\n",
       "      <td>41820</td>\n",
       "      <td>Xuhui District, Shanghai, China</td>\n",
       "      <td>31.172093</td>\n",
       "      <td>121.434525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467815</td>\n",
       "      <td>62.697270</td>\n",
       "      <td>56.232140</td>\n",
       "      <td>24.591354</td>\n",
       "      <td>0.316244</td>\n",
       "      <td>184.798786</td>\n",
       "      <td>181.544481</td>\n",
       "      <td>130.509592</td>\n",
       "      <td>0.215941</td>\n",
       "      <td>[#787839, #3f3819, #b9b683]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iNatStruct = result\n",
    "iNatStruct[\"Hex_Color_Code\"] = ord_hex_code\n",
    "#iNatStruct[\"Hex_Color_Code\"] = hex_code\n",
    "iNatStruct.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "8392b80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 2D list to numpy.ndarray and get the transposed object with the T attribute\n",
    "# Remove and then add RGB columns to different location\n",
    "iNatStruct['RGB1'] = pd.DataFrame(np.array([Color_Names_1]).T)\n",
    "RGB1 = iNatStruct.pop('RGB1')\n",
    "iNatStruct.insert(13, 'RGB1', RGB1)\n",
    "\n",
    "iNatStruct['RGB2'] = pd.DataFrame(np.array([Color_Names_2]).T)\n",
    "RGB2 = iNatStruct.pop('RGB2')\n",
    "iNatStruct.insert(18, 'RGB2', RGB2)\n",
    "\n",
    "iNatStruct['RGB3'] = pd.DataFrame(np.array([Color_Names_3]).T)\n",
    "RGB3 = iNatStruct.pop('RGB3')\n",
    "iNatStruct.insert(23, 'RGB3', RGB3)\n",
    "\n",
    "Hex_Code = iNatStruct.pop('Hex_Color_Code')\n",
    "iNatStruct.insert(10, 'Hex_Color_Code', Hex_Code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301adef6",
   "metadata": {},
   "source": [
    "# Size Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1112ee1b",
   "metadata": {},
   "source": [
    "#### Define tag function: detects edges of object, tags with a rectangle and returns the width and height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "2de89dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag(img):\n",
    "    blurred = cv2.blur(img, (3,3))\n",
    "    canny = cv2.Canny(blurred, 50, 200)\n",
    "    \n",
    "    pts = np.argwhere(canny>0)\n",
    "    y1,x1 = pts.min(axis=0)\n",
    "    y2,x2 = pts.max(axis=0)\n",
    "    \n",
    "    w = (x2-x1) # width\n",
    "    h = (y2-y1) # height\n",
    "    \n",
    "    return [x1, y1, w,h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "eacd550f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tag(imgNat))\n",
    "#print(tag(imgNat)[0])\n",
    "#print(tag(imgNat)[1])\n",
    "#ex = [tag(imgNat),tag(imgNat)]\n",
    "#np.array(tag(imgNat))\n",
    "#np.array(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "3419c92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pylab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "ad4f48c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_tag and h_tag is 425 312\n",
      "w1 and h1 is 164 313\n",
      "w_tag and h_tag is 499 332\n",
      "w1 and h1 is 500 333\n",
      "w_tag and h_tag is 499 332\n",
      "w1 and h1 is 462 169\n",
      "w_tag and h_tag is 387 240\n",
      "w1 and h1 is 383 217\n"
     ]
    }
   ],
   "source": [
    "contArea = []\n",
    "width = []\n",
    "height = []\n",
    "ratio = []\n",
    "extentInfo = []\n",
    "solidityInfo = []\n",
    "angleInfo = []\n",
    "\n",
    "for img in iNatStruct[\"Image_Link\"]: \n",
    "    req = urllib.request.urlopen(img)\n",
    "    arr = np.asarray(bytearray(req.read()), dtype=np.uint8)\n",
    "    imgNat = cv2.imdecode(arr, -1)\n",
    "    imgray = cv2.cvtColor(imgNat, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(imgray, (5,5), 0)\n",
    "    thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    imgNat = cv2.cvtColor(imgNat,cv2.COLOR_BGR2RGB) #convert bgr to rgb\n",
    "    largest_contour = max(contours, key=cv2.contourArea) # grab maximum contour\n",
    "    \n",
    "    cv2.drawContours(imgNat, largest_contour, -1, (0, 255, 0), 3)\n",
    "    \n",
    "    # create black mask\n",
    "    mask = np.zeros_like(imgray)\n",
    "    # fill the new mask with the shape of the largest contour \n",
    "    #cv2.fillPoly(mask, [contours[0]], 255) >> grabs smallest contour\n",
    "    cv2.fillPoly(mask, [largest_contour], 255)\n",
    "    # current mask copy\n",
    "    res_mask = np.copy(mask)\n",
    "    res_mask[mask == 0] = cv2.GC_BGD # obvious background pixels\n",
    "    res_mask[mask == 255] = cv2.GC_PR_BGD # probable background pixels\n",
    "    res_mask[mask == 255] = cv2.GC_FGD # obvious foreground pixels\n",
    "\n",
    "    # create a mask for obvious and probable foreground pixels\n",
    "    # all the obvious foreground pixels will be white and all the probable foreground pixels will be black\n",
    "    mask2 = np.where((res_mask == cv2.GC_FGD) | (res_mask == cv2.GC_PR_FGD),255,0).astype('uint8')\n",
    "\n",
    "    # create `new_mask3d` from `mask2` but with 3 dimensions instead of 2\n",
    "    new_mask3d = np.repeat(mask2[:, :, np.newaxis], 3, axis=2)\n",
    "    mask3d = new_mask3d\n",
    "    mask3d[new_mask3d > 0] = 255.0\n",
    "    mask3d[mask3d > 255] = 255.0\n",
    "    # apply Gaussian blurring to smoothen out the edges\n",
    "    mask3d = cv2.GaussianBlur(mask3d, (5, 5), 0)\n",
    "    #show('Foreground mask', mask3d)\n",
    "    \n",
    "    # create the foreground image by zeroing out the pixels where `mask2` has black pixels\n",
    "    foreground = np.copy(imgNat).astype(float)\n",
    "    foreground[mask2 == 0] = 0\n",
    "    \n",
    "    # work with black background\n",
    "    imgNat_black = Image.fromarray(foreground.astype(np.uint8))\n",
    "    # Only pass through non-transparent pixels, i.e. those where A!=0 in the RGBA quad\n",
    "    #na = np.array([f for f in imgfile.getdata() if f[2] !=0], np.uint8)\n",
    "    \n",
    "    ## apply contour to created black background image\n",
    "    #req = imgNat_black\n",
    "    #arr_black = np.asarray(imgNat_black.getdata(), dtype=np.uint8)\n",
    "    #imgNat_new = cv2.imdecode(arr_black, -1)\n",
    "    #imgray = cv2.cvtColor(imgNat_new, cv2.COLOR_BGR2GRAY)\n",
    "    #blur = cv2.GaussianBlur(imgray, (5,5), 0)\n",
    "    #thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "    #contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    #imgNat = cv2.cvtColor(imgNat,cv2.COLOR_BGR2RGB) #convert bgr to rgb\n",
    "    #largest_contour = max(contours, key=cv2.contourArea) # grab maximum contour\n",
    "    #cv2.drawContours(imgNat_black, contours, -1, (0, 255, 0), 3)\n",
    "    \n",
    "    #plt.imshow(imgNat)\n",
    "    #plt.imshow(imgNat_black)\n",
    "    \n",
    "    # Contour Area\n",
    "    #cnt = contours[1] # throws an error for some reason..?\n",
    "    #cnt = contours[0] # this works\n",
    "    cnt = largest_contour\n",
    "\n",
    "    # Rotated rectangle > not sure if we want to use this\n",
    "    #rect = cv2.minAreaRect(cnt)\n",
    "    #box = cv2.boxPoints(rect)\n",
    "    #box = np.int0(box)\n",
    "    #x,y,w,h = cv2.boundingRect(box)\n",
    "    #print(\"w and h is\", w, h)\n",
    "    #print(\"x is\", x)\n",
    "    #print(\"y is\", y)\n",
    "    \n",
    "    # tagged attributes\n",
    "    x_tag, y_tag, w_tag, h_tag = tag(imgNat)\n",
    "    print(\"w_tag and h_tag is\", w_tag, h_tag)\n",
    "    #print(\"x_tag is\", x_tag)\n",
    "    #print(\"y_tag is\", y_tag)\n",
    "    \n",
    "    # set bounding rectangle around object\n",
    "    x1,y1,w1,h1 = cv2.boundingRect(cnt)\n",
    "    print(\"w1 and h1 is\", w1, h1)\n",
    "    #print(\"x1 is\", x1)\n",
    "    #print(\"y1 is\", y1)\n",
    "    \n",
    "    # Contour Area\n",
    "    area = cv2.contourArea(cnt)\n",
    "    \n",
    "    # Orientation (Angle)\n",
    "    if area < 5:\n",
    "        angle = float(\"NaN\")\n",
    "    else:\n",
    "        (x,y),(MA,ma),angle = cv2.fitEllipse(cnt)\n",
    "    \n",
    "    # Aspect Ratio\n",
    "    #aspect_ratio = float(w1)/h1\n",
    "    aspect_ratio = float(w_tag)/(h_tag)\n",
    "    \n",
    "    # Extent\n",
    "    #rect_area = w1*h1\n",
    "    rect_area = w_tag*h_tag\n",
    "    extent = float(area)/rect_area\n",
    "\n",
    "    # Solidity\n",
    "    hull = cv2.convexHull(cnt)\n",
    "    hull_area = cv2.contourArea(hull)\n",
    "    \n",
    "    if hull_area == 0:\n",
    "        solidity = float(\"NaN\") # replace solidity to Nan when hull_area is 0\n",
    "        \n",
    "    else:\n",
    "        solidity = float(area)/hull_area\n",
    "\n",
    "    # Orientation (angle)\n",
    "    #(x,y),(MA,ma),angle = cv2.fitEllipse(cnt)\n",
    "        \n",
    "    contArea.append(area)\n",
    "    width.append(w_tag)\n",
    "    height.append(h_tag)\n",
    "    #width.append(w1)\n",
    "    #height.append(h1)\n",
    "    ratio.append(aspect_ratio)\n",
    "    extentInfo.append(extent)\n",
    "    solidityInfo.append(solidity)\n",
    "    angleInfo.append(angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "a5ebdb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Attempt on image with background of clear white\n",
    "# req = urllib.request.urlopen(iNatStruct[\"Image_Link\"][8])\n",
    "# arr = np.asarray(bytearray(req.read()), dtype=np.uint8)\n",
    "# img1 = cv2.imdecode(arr, -1)\n",
    "# blurred = cv2.blur(img1, (3,3))\n",
    "# canny = cv2.Canny(blurred, 50, 200)\n",
    "\n",
    "# ## find the non-zero min-max coords of canny\n",
    "# pts = np.argwhere(canny>0)\n",
    "# y1,x1 = pts.min(axis=0)\n",
    "# y2,x2 = pts.max(axis=0)\n",
    "\n",
    "# ## crop the region\n",
    "# cropped = img1[y1:y2, x1:x2]\n",
    "# #cv2.imwrite(\"cropped.png\", cropped)\n",
    "\n",
    "# tagged = cv2.rectangle(img1.copy(), (x1,y1), (x2,y2), (0,255,0), 3, cv2.LINE_AA)\n",
    "# plt.imshow(tagged)\n",
    "# #cv2.imshow(\"tagged\", tagged)\n",
    "# #cv2.waitKey()\n",
    "\n",
    "# print(x2-x1)\n",
    "# print(y2-y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "1e7949e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_Label</th>\n",
       "      <th>Image_Link</th>\n",
       "      <th>Species</th>\n",
       "      <th>User</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Seconds</th>\n",
       "      <th>Place</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>...</th>\n",
       "      <th>B3</th>\n",
       "      <th>RGB3</th>\n",
       "      <th>Prop3</th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Contour_Area</th>\n",
       "      <th>Aspect_Ratio</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Solidity</th>\n",
       "      <th>Angle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p1</td>\n",
       "      <td>https://inaturalist-open-data.s3.amazonaws.com...</td>\n",
       "      <td>Flowering Plants</td>\n",
       "      <td>jiayuelin</td>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>11:37:00</td>\n",
       "      <td>41820</td>\n",
       "      <td>Xuhui District, Shanghai, China</td>\n",
       "      <td>31.173552</td>\n",
       "      <td>121.443451</td>\n",
       "      <td>...</td>\n",
       "      <td>59.332842</td>\n",
       "      <td>olivedrab</td>\n",
       "      <td>0.199246</td>\n",
       "      <td>425</td>\n",
       "      <td>312</td>\n",
       "      <td>29075.0</td>\n",
       "      <td>1.362179</td>\n",
       "      <td>0.219268</td>\n",
       "      <td>0.791727</td>\n",
       "      <td>28.653761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p2</td>\n",
       "      <td>https://inaturalist-open-data.s3.amazonaws.com...</td>\n",
       "      <td>五爪金龙</td>\n",
       "      <td>jiayuelin</td>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>11:37:00</td>\n",
       "      <td>41820</td>\n",
       "      <td>Xuhui District, Shanghai, China</td>\n",
       "      <td>31.184283</td>\n",
       "      <td>121.435212</td>\n",
       "      <td>...</td>\n",
       "      <td>209.270963</td>\n",
       "      <td>mediumpurple</td>\n",
       "      <td>0.140907</td>\n",
       "      <td>499</td>\n",
       "      <td>332</td>\n",
       "      <td>160978.0</td>\n",
       "      <td>1.503012</td>\n",
       "      <td>0.971690</td>\n",
       "      <td>0.971690</td>\n",
       "      <td>81.539787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p3</td>\n",
       "      <td>https://inaturalist-open-data.s3.amazonaws.com...</td>\n",
       "      <td>Plants</td>\n",
       "      <td>jiayuelin</td>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>11:37:00</td>\n",
       "      <td>41820</td>\n",
       "      <td>Xuhui District, Shanghai, China</td>\n",
       "      <td>31.177380</td>\n",
       "      <td>121.436928</td>\n",
       "      <td>...</td>\n",
       "      <td>61.590377</td>\n",
       "      <td>darkolivegreen</td>\n",
       "      <td>0.260402</td>\n",
       "      <td>499</td>\n",
       "      <td>332</td>\n",
       "      <td>38861.0</td>\n",
       "      <td>1.503012</td>\n",
       "      <td>0.234572</td>\n",
       "      <td>0.662569</td>\n",
       "      <td>155.767166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p4</td>\n",
       "      <td>https://inaturalist-open-data.s3.amazonaws.com...</td>\n",
       "      <td>Plants</td>\n",
       "      <td>jiayuelin</td>\n",
       "      <td>2022-05-19</td>\n",
       "      <td>11:37:00</td>\n",
       "      <td>41820</td>\n",
       "      <td>Xuhui District, Shanghai, China</td>\n",
       "      <td>31.172093</td>\n",
       "      <td>121.434525</td>\n",
       "      <td>...</td>\n",
       "      <td>130.509592</td>\n",
       "      <td>darkkhaki</td>\n",
       "      <td>0.215941</td>\n",
       "      <td>387</td>\n",
       "      <td>240</td>\n",
       "      <td>53230.0</td>\n",
       "      <td>1.612500</td>\n",
       "      <td>0.573105</td>\n",
       "      <td>0.751597</td>\n",
       "      <td>104.551666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 33 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iNatStruct[\"Width\"] = width\n",
    "iNatStruct[\"Height\"] = height\n",
    "iNatStruct[\"Contour_Area\"] = contArea\n",
    "iNatStruct[\"Aspect_Ratio\"] = ratio\n",
    "iNatStruct[\"Extent\"] = extentInfo\n",
    "iNatStruct[\"Solidity\"] = solidityInfo\n",
    "iNatStruct[\"Angle\"] = angleInfo\n",
    "iNatStruct.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4ffca9",
   "metadata": {},
   "source": [
    "### check black-background picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "a005cd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#black_back = []\n",
    "#for img in iNatStruct[\"Image_Link\"]: \n",
    "#    req = urllib.request.urlopen(img)\n",
    "#    arr = np.asarray(bytearray(req.read()), dtype=np.uint8)\n",
    "#    imgNat_con = cv2.imdecode(arr, -1)\n",
    "#    imgNat = cv2.imdecode(arr, -1)\n",
    "#    imgray = cv2.cvtColor(imgNat, cv2.COLOR_BGR2GRAY)\n",
    "#    blur = cv2.GaussianBlur(imgray, (5,5), 0)\n",
    "#    thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "#    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#    cv2.drawContours(imgNat_con, contours, -1, (0, 255, 0), 3)\n",
    "    #plt.imshow(imgNat_con)\n",
    "    \n",
    "#    imgNat = cv2.cvtColor(imgNat,cv2.COLOR_BGR2RGB) #convert bgr to rgb\n",
    "    \n",
    "    # grab largest contour\n",
    "#    largest_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "\n",
    "# create a black `mask` the same size as the original grayscale image \n",
    "#    mask = np.zeros_like(imgray)\n",
    "# fill the new mask with the shape of the largest contour\n",
    "#    cv2.fillPoly(mask, [largest_contour], 255)\n",
    "# create a copy of the current mask\n",
    "#    res_mask = np.copy(mask)\n",
    "#    res_mask[mask == 0] = cv2.GC_BGD # obvious background pixels\n",
    "#    res_mask[mask == 255] = cv2.GC_PR_BGD # probable background pixels\n",
    "#    res_mask[mask == 255] = cv2.GC_FGD # obvious foreground pixels\n",
    "\n",
    "# create a mask for obvious and probable foreground pixels\n",
    "#    mask2 = np.where((res_mask == cv2.GC_FGD) | (res_mask == cv2.GC_PR_FGD),255,0).astype('uint8')\n",
    "\n",
    "# create `new_mask3d` from `mask2` but with 3 dimensions instead of 2\n",
    "#    new_mask3d = np.repeat(mask2[:, :, np.newaxis], 3, axis=2)\n",
    "#    mask3d = new_mask3d\n",
    "#    mask3d[new_mask3d > 0] = 255.0\n",
    "#    mask3d[mask3d > 255] = 255.0\n",
    "# apply Gaussian blurring to smoothen out the edges a bit\n",
    "#    mask3d = cv2.GaussianBlur(mask3d, (5, 5), 0)\n",
    "    #show('Foreground mask', mask3d)\n",
    "\n",
    "# create the foreground image by zeroing out the pixels where `mask2` has black pixels\n",
    "#    foreground = np.copy(imgNat).astype(float)\n",
    "#    foreground[mask2 == 0] = 0\n",
    "    #plt.imshow(foreground.astype(np.uint8))\n",
    "#    black_back.append(foreground.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "a73c1527",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(black_back[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "2ecc7479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt on p1\n",
    "#req = urllib.request.urlopen(iNatStruct[\"Image_Link\"][11])\n",
    "#arr = np.asarray(bytearray(req.read()), dtype=np.uint8)\n",
    "#imgNat = cv2.imdecode(arr, -1)\n",
    "#imgray = cv2.cvtColor(imgNat, cv2.COLOR_BGR2GRAY)\n",
    "#blur = cv2.GaussianBlur(imgray, (5,5), 0)\n",
    "#thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "#contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#cv2.drawContours(imgNat, contours, -1, (0, 255, 0), 3)\n",
    "#plt.imshow(imgNat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "d1edfbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt on image with black background \n",
    "#blurred = cv2.blur(black_back[11], (3,3))\n",
    "#canny = cv2.Canny(blurred, 50, 200)\n",
    "\n",
    "## find the non-zero min-max coords of canny\n",
    "#pts = np.argwhere(canny>0)\n",
    "#y1,x1 = pts.min(axis=0)\n",
    "#y2,x2 = pts.max(axis=0)\n",
    "\n",
    "## crop the region\n",
    "#cropped = black_back[11][y1:y2, x1:x2]\n",
    "#cv2.imwrite(\"cropped.png\", cropped)\n",
    "\n",
    "#tagged = cv2.rectangle(black_back[11].copy(), (x1,y1), (x2,y2), (0,255,0), 3, cv2.LINE_AA)\n",
    "#plt.imshow(tagged)\n",
    "#cv2.imshow(\"tagged\", tagged)\n",
    "#cv2.waitKey()\n",
    "\n",
    "#print(x2-x1)\n",
    "#print(y2-y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "ff17a945",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag(black_back[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "9664f1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iNatStruct.to_excel(pd.ExcelWriter, sheet_name='Sheet1', na_rep='', \n",
    "#                   float_format=None, columns=None, header=True, index=True, \n",
    "#                   index_label=None, startrow=0, startcol=0, engine=None, \n",
    "#                   merge_cells=True, encoding=None, inf_rep='inf', verbose=True, \n",
    "#                   freeze_panes=None, storage_options=None)\n",
    "\n",
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter('iNatStruct.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Convert the dataframe to an XlsxWriter Excel object.\n",
    "iNatStruct.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ec6bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to csv file\n",
    "iNatStruct.to_csv('iNatStruct.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd96370b791b4e4b2b47a3667ae3e18217ec16788d92c294082a8f273ec99fef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
